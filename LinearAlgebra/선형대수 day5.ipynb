{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b94db2",
   "metadata": {},
   "source": [
    "# eigenvector & eigenvalue\n",
    "    Ax = 람다 * x 에서 x는 eigenvector, 람다가 eigenvalue\n",
    "    x값이 변해도 람다는 고정 ex) x가 3배 늘어도 양변에 3배 늘어나므로 람다는 고정\n",
    "    따라서 eigenvector는 방향을 바꾸지 않는 벡터임. 길이만 람다만큼 늘어남\n",
    "    따라서 eigenvector는 여러개 나올 수 있음 -> eigenvector의 선형결합으로 무한히 많이 나올 수 있으므로 linearly independent한 eigenvector을 찾는 것이 관건\n",
    "    eignenvalue에 대해 linearly independent한 eigenvector는 여러개가 나올 수 있다!\n",
    "    eigenvector을 통해 Ax를 계산하는 것보다 computational time을 줄일 수 있음\n",
    "    \n",
    "    Ax-람다x = 0 -> (A - 람다I)x = 0 => 행렬 A의 대각원소에 람다만큼 빼고 거기에 벡터 x를 곱하면 0이 나와야함\n",
    "    벡터 x가 0벡터가 나오면 의미가 없으므로 nonzero인 해를 갖기 위해서는 A-람다I 행렬의 열벡터가 linearly dependent 해야한다.\n",
    "        -> linearly independent 할 때의 해는 0밖에 없으므로\n",
    "    linearly dependent 한 행렬은 역행렬이 없음(행렬식=0). linearly independet 해야 역행렬이 있음(행렬식!=0).\n",
    "    A-람다I의 determinant=0 을 해줘야 eigenvector가 0이 아닌 다른 값을 가질 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73a0b0",
   "metadata": {},
   "source": [
    "## characteristic equation\n",
    "    det(A-람다I) = 0 을 characteristic equation 이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae75b6e",
   "metadata": {},
   "source": [
    "## null space\n",
    "    Ax = 0 을 만족하는 모든 해 x의 subspace를 null space라고 한다. 어떤 null space든지 0벡터는 포함한다.\n",
    "    행렬 A의 각 행에 대해 x는 모두 수직이어야함(0이므로). 행렬이 5차원일 때 linear independent한 basis가 3개라면 직교하는 축이 3개가 된다.\n",
    "    그 축들(3개) 외의 나머지 두개의 축은 또 3개의 축들과 각각 수직이어야 하므로 null space의 차원은 이때는 2차원이 된다.\n",
    "    -> 요약하자면 전체공간에서 수직으로 만나는 두개의 공간으로 양분할 수 있음(orthogonal complement)\n",
    "    ex) 전체 차원이 5차원, A의 column space가 2차원이면 걔랑 수직인 벡터들을 다 모아놓으면 그 subspace의 차원은 5-2 = 3차원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da4ea7",
   "metadata": {},
   "source": [
    "## charateristic equation의 해, 람다 -> 고유벡터\n",
    "det(A-람다I)=0 의 방정식을 통해서 eigenvalue들을 모두 구해야하는데 5 * 5 행렬에 대해서는 행렬식이 5차방정식이 나온다. 만약 (람다-a)^3 * (람다-b) * (람다-c)=0 이 나오면 람다=a 일 때는 선형독립인 고유벡터가 3개까지 나올 수 있고 나머지 b,c에 대해서는 1개까지밖에 나오지 않는다(차수로 판단). 모두 최대로 고유벡터가 나온다고 가정하면 다섯개의 eigenvector 들은 서로 linearly independent하고 이 다섯개의 벡터의 span은 5차원을 모두 뒤덮을 수 있다. 만약 a에 대해서 고유벡터가 두개나오고 나머지는 하나씩 나오면 4개의 eigenvector가 생기고 이 span은 5차원을 모두 뒤덮을 수 없다.\n",
    "만약 방정식이 중근이 없고 람다값이 다 다르게 나오면 고유값 하나에 대해 고유벡터는 하나는 존재해야한다. 그 이유는 행렬식=0->linearly dependent->non zero존재."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e40e9",
   "metadata": {},
   "source": [
    "## diagonalization(대각화)\n",
    "    square matrix A에 대해 A의 고유벡터로 이루어진 square matrix V와 그 역행렬 V-1로 식을 만든다 -> V-1AV -> 이 식의 결과는 대각행렬 D가 나오는데 대각 성분들은 A의 고유벡터의 각각의 고유값이다.\n",
    "    diagonalization 이 가능하기 위해서는 V가 역행렬이 존재해야되고, 그러기 위해서는 V의 열벡터들 즉, eigenvector 들이 선형독립 해야한다. ex) A는 5차원 square matrix -> V도 5*5 행렬 -> V의 inverse가 존재하기 위해서는 A의 고유벡터들 v가 5개가 나와야하며 이것들은 선형독립 해야함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277a6c3",
   "metadata": {},
   "source": [
    " # eigendecomposition\n",
    "    D = V-1AV 의 대각화 식을 A = VDV-1 로 바꾼 것이 eigendecomposition 이다. A의 고유벡터로 이루어진 V, A의 고유값으로 이루어진 D.\n",
    "    V는 선형독립인 고유벡터들로 이루어져 있다. 전체 벡터 공간에서 존재하는 임의의 벡터는 V의 고유벡터의 선형결합으로 표현이 가능하다.\n",
    "    \n",
    "    linear transformation 은 T(x) = Ax 의 꼴이다. Ax = VDV-1 * x -> V(D(V-1 * x) 의 합성함수 꼴로 나타낼 수 있다.\n",
    "        1. V-1 * x\n",
    "            y = V-1 * x -> y*V = x (y가 구해야 하는 해임. 따라서 ax = b 꼴임) x 주어져 있고, \n",
    "            V도 고유벡터의 행렬이므로 주어져 있다. 따라서 y구할 수 있음-> (2,1)이라고 가정\n",
    "        2. D * y     \n",
    "            x = y*V 의 양변에 A를 곱하면 Ax = A*(2,1)*V -> A*2v1 + A*v2 -> 2*Av1 + A*v2 의 꼴로 바꾸면 Av는 람다*v 이므로 \n",
    "            행렬A*벡터v의 연산을 하지 않고 벡터 v의 상수배로 computational advantage를 끌어낼 수 있다.\n",
    "            이 논리대로 D*y = z 는 행렬*벡터가 아닌 벡터의 상수배로 즉, element-wise 하게 z 연산 가능\n",
    "        3. V * z\n",
    "            V는 고유벡터 v의 벡터. D*y를 한 z의 값을 V에 곱해준 것이 dimension-wise scaling. 요약하면 x벡터를 구하기 위해 고유벡터 v1,v2에 y좌표를 곱해 구하는데 x벡터가 주어져 있으므로 역으로 y를 구해주고 거기에 D를 곱하면 대각행렬이므로 element-wise하게 z를 구하고 그 z에 다시 고유벡터 v1,v2를 곱하면 T(x)의 결과 벡터가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfaa8a1",
   "metadata": {},
   "source": [
    "# change of basis의 관점\n",
    "    위의 내용을 기하학적으로 보면 존재하는 x벡터는 (1,0), (0,1)의 basis상에서의 좌표로 존재한다. 여기서 고유벡터 x1,x2를 기준으로\n",
    "    x벡터를 표현하면 a*v1 + b+v2 = ij 기반의 x벡터의 좌표. -> 고유벡터 v1,v2를 basis vector로 하는 (a,b)가 새로운 좌표가 된다.\n",
    "    그 (a,b)에 eigenvalue(D)를 곱한 결과 z -> 다시 고유벡터V와 z를 곱하면 애초에 linear transformation한 결과 Ax가 됨(basis가 i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3ec86",
   "metadata": {},
   "source": [
    "## A^k 를 통한 linear transformation\n",
    "    A를 거듭곱한 A*A*A*...*A*x는 eigendecomposition으로 A^k = VD^kV-1 로 나타낼 수 있다. A^k*x 는 VD^kV-1 * x 이고 V-1*x = y를 구하고\n",
    "    D^k는 대각 성분들을 단순이 k번 곱한 행렬이므로 거기에 y를 곱하면 element-wise scaling으로 행렬이 나오고 그것을 다시 V를 곱해 원래\n",
    "    basis로 돌리는 것으로 볼 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
